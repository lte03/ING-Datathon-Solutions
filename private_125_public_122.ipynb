{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:12:24.004265Z",
     "iopub.status.busy": "2025-10-19T17:12:24.003980Z",
     "iopub.status.idle": "2025-10-19T17:12:24.014184Z",
     "shell.execute_reply": "2025-10-19T17:12:24.013338Z",
     "shell.execute_reply.started": "2025-10-19T17:12:24.004247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def recall_at_k(y_true, y_prob, k=0.1):\n",
    "    \"\"\"\n",
    "    Tahmin edilen olasılıkların en üst k%'sını pozitif etiketleyerek recall değerini hesaplar.\n",
    "\n",
    "    Parametreler:\n",
    "        y_true (list): Gerçek ikili etiketler.\n",
    "        y_prob (list): Tahmin edilen olasılıklar.\n",
    "        k (float): Pozitif etiketlenecek olasılıkların yüzdelik dilimi (varsayılan 0.1).\n",
    "\n",
    "    Döndürür:\n",
    "        float: En iyi k% tahminlerindeki recall oranı.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    n = len(y_true)\n",
    "    m = max(1, int(np.round(k * n)))\n",
    "    order = np.argsort(-y_prob, kind=\"mergesort\")\n",
    "    top = order[:m]\n",
    "\n",
    "    tp_at_k = y_true[top].sum()\n",
    "    P = y_true.sum()\n",
    "\n",
    "    return float(tp_at_k / P) if P > 0 else 0.0\n",
    "\n",
    "\n",
    "def lift_at_k(y_true, y_prob, k=0.1):\n",
    "    \"\"\"\n",
    "    Tahmin edilen olasılıkların en üst k%'sını pozitif etiketleyerek lift (precision/prevalence) değerini hesaplar.\n",
    "\n",
    "    Parametreler:\n",
    "        y_true (list): Gerçek ikili etiketler.\n",
    "        y_prob (list): Tahmin edilen olasılıklar.\n",
    "        k (float): Pozitif etiketlenecek olasılıkların yüzdelik dilimi (varsayılan 0.1).\n",
    "\n",
    "    Döndürür:\n",
    "        float: En iyi k% tahminlerindeki lift değeri.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    n = len(y_true)\n",
    "    m = max(1, int(np.round(k * n)))\n",
    "    order = np.argsort(-y_prob, kind=\"mergesort\")\n",
    "    top = order[:m]\n",
    "\n",
    "    tp_at_k = y_true[top].sum()\n",
    "    precision_at_k = tp_at_k / m\n",
    "    prevalence = y_true.mean()\n",
    "\n",
    "    return float(precision_at_k / prevalence) if prevalence > 0 else 0.0\n",
    "\n",
    "\n",
    "def convert_auc_to_gini(auc):\n",
    "    \"\"\"\n",
    "    ROC AUC skorunu Gini katsayısına dönüştürür.\n",
    "\n",
    "    Gini katsayısı, ROC AUC skorunun doğrusal bir dönüşümüdür.\n",
    "\n",
    "    Parametreler:\n",
    "        auc (float): ROC AUC skoru (0 ile 1 arasında).\n",
    "\n",
    "    Döndürür:\n",
    "        float: Gini katsayısı (-1 ile 1 arasında).\n",
    "    \"\"\"\n",
    "    return 2 * auc - 1\n",
    "\n",
    "\n",
    "def ing_hubs_datathon_metric(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Gini, recall@10% ve lift@10% metriklerini birleştiren özel bir metrik hesaplar.\n",
    "\n",
    "    Metrik, her bir skoru bir baseline modelin metrik değerlerine göre oranlar ve aşağıdaki ağırlıkları uygular:\n",
    "    - Gini: %40\n",
    "    - Recall@10%: %30\n",
    "    - Lift@10%: %30\n",
    "\n",
    "    Parametreler:\n",
    "        y_true (list): Gerçek ikili etiketler.\n",
    "        y_prob (list): Tahmin edilen olasılıklar.\n",
    "\n",
    "    Döndürür:\n",
    "        float: Ağırlıklandırılmış bileşik skor.\n",
    "    \"\"\"\n",
    "    # final metrik için ağırlıklar\n",
    "    score_weights = {\n",
    "        \"gini\": 0.4,\n",
    "        \"recall_at_10perc\": 0.3,\n",
    "        \"lift_at_10perc\": 0.3,\n",
    "    }\n",
    "\n",
    "    # baseline modelin her bir metrik için değerleri\n",
    "    baseline_scores = {\n",
    "        \"roc_auc\": 0.6925726757936908,\n",
    "        \"recall_at_10perc\": 0.18469015795868773,\n",
    "        \"lift_at_10perc\": 1.847159286784029,\n",
    "    }\n",
    "\n",
    "    # y_prob tahminleri için metriklerin hesaplanması\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    recall_at_10perc = recall_at_k(y_true, y_prob, k=0.1)\n",
    "    lift_at_10perc = lift_at_k(y_true, y_prob, k=0.1)\n",
    "\n",
    "    new_scores = {\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"recall_at_10perc\": recall_at_10perc,\n",
    "        \"lift_at_10perc\": lift_at_10perc,\n",
    "    }\n",
    "\n",
    "    # roc auc değerlerinin gini değerine dönüştürülmesi\n",
    "    baseline_scores[\"gini\"] = convert_auc_to_gini(baseline_scores[\"roc_auc\"])\n",
    "    new_scores[\"gini\"] = convert_auc_to_gini(new_scores[\"roc_auc\"])\n",
    "\n",
    "    # baseline modeline oranlama\n",
    "    final_gini_score = new_scores[\"gini\"] / baseline_scores[\"gini\"]\n",
    "    final_recall_score = new_scores[\"recall_at_10perc\"] / baseline_scores[\"recall_at_10perc\"]\n",
    "    final_lift_score = new_scores[\"lift_at_10perc\"] / baseline_scores[\"lift_at_10perc\"]\n",
    "\n",
    "    # ağırlıklandırılmış metriğin hesaplanması\n",
    "    final_score = (\n",
    "        final_gini_score * score_weights[\"gini\"] +\n",
    "        final_recall_score * score_weights[\"recall_at_10perc\"] + \n",
    "        final_lift_score * score_weights[\"lift_at_10perc\"]\n",
    "    )\n",
    "    return final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:12:26.715248Z",
     "iopub.status.busy": "2025-10-19T17:12:26.714983Z",
     "iopub.status.idle": "2025-10-19T17:12:26.720048Z",
     "shell.execute_reply": "2025-10-19T17:12:26.719306Z",
     "shell.execute_reply.started": "2025-10-19T17:12:26.715228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Dosya yollarını tanımlayalım\n",
    "train_ref_path = '/kaggle/input/ing-hubs-turkiye-datathon/referance_data.csv'\n",
    "test_ref_path = '/kaggle/input/ing-hubs-turkiye-datathon/referance_data_test.csv'\n",
    "customers_path = '/kaggle/input/ing-hubs-turkiye-datathon/customers.csv'\n",
    "customer_history_path = '/kaggle/input/ing-hubs-turkiye-datathon/customer_history.csv'\n",
    "\n",
    "# Tüm CSV dosyalarını LazyFrame olarak oku\n",
    "train_ref_data = pl.scan_csv(train_ref_path)\n",
    "test_ref_data = pl.scan_csv(test_ref_path)\n",
    "customers = pl.scan_csv(customers_path)\n",
    "customer_history = pl.scan_csv(customer_history_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:11:06.178526Z",
     "iopub.status.busy": "2025-10-19T17:11:06.178252Z",
     "iopub.status.idle": "2025-10-19T17:11:06.182199Z",
     "shell.execute_reply": "2025-10-19T17:11:06.181322Z",
     "shell.execute_reply.started": "2025-10-19T17:11:06.178508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "customer_history =inflation_adjusted_history.drop([\n",
    "    'mobile_eft_all_amt',\n",
    "    'cc_transaction_all_amt',\n",
    "    'year_month',\n",
    "    'cpi_index'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:12:31.099925Z",
     "iopub.status.busy": "2025-10-19T17:12:31.099643Z",
     "iopub.status.idle": "2025-10-19T17:12:31.107055Z",
     "shell.execute_reply": "2025-10-19T17:12:31.106279Z",
     "shell.execute_reply.started": "2025-10-19T17:12:31.099903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37/4073466029.py:8: PerformanceWarning: Resolving the schema of a LazyFrame is a potentially expensive operation. Use `LazyFrame.collect_schema()` to get the schema without this warning.\n",
      "  churn=pl.lit(None, dtype=train_ref_data.schema[\"churn\"])\n",
      "/tmp/ipykernel_37/4073466029.py:11: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
      "  test_ref_data = test_ref_data.select(train_ref_data.columns)\n"
     ]
    }
   ],
   "source": [
    "train_ref_data = train_ref_data.with_columns(split=pl.lit(\"Train\"))\n",
    "\n",
    "# Test setine, train setiyle aynı şemaya sahip olması için null bir 'churn' kolonu ekle.\n",
    "# Bu, 'concat' işleminin çalışması için gereklidir.\n",
    "# 'churn' kolonunun veri tipini (dtype) train setinden dinamik olarak alıyoruz.\n",
    "test_ref_data = test_ref_data.with_columns(\n",
    "    split=pl.lit(\"Test\"),\n",
    "    churn=pl.lit(None, dtype=train_ref_data.schema[\"churn\"])\n",
    ")\n",
    "\n",
    "test_ref_data = test_ref_data.select(train_ref_data.columns)\n",
    "ref_data = pl.concat([train_ref_data, test_ref_data])\n",
    "\n",
    "\n",
    "ref_data = ref_data.with_columns(\n",
    "    ref_date=pl.col('ref_date').str.to_date(\"%Y-%m-%d\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:12:32.867129Z",
     "iopub.status.busy": "2025-10-19T17:12:32.866410Z",
     "iopub.status.idle": "2025-10-19T17:12:32.871333Z",
     "shell.execute_reply": "2025-10-19T17:12:32.870526Z",
     "shell.execute_reply.started": "2025-10-19T17:12:32.867105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "customers = customers.with_columns([\n",
    "    pl.col(\"work_sector\").fill_null(\"Not Working\"),\n",
    "    ((pl.col(\"tenure\") / 365) / pl.col(\"age\")).alias(\"tenure_per_age\")\n",
    "])\n",
    "\n",
    "ref_data_v2 = ref_data.join(\n",
    "    customers,\n",
    "    on=\"cust_id\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:12:35.509331Z",
     "iopub.status.busy": "2025-10-19T17:12:35.508848Z",
     "iopub.status.idle": "2025-10-19T17:12:35.515376Z",
     "shell.execute_reply": "2025-10-19T17:12:35.514729Z",
     "shell.execute_reply.started": "2025-10-19T17:12:35.509307Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37/342553364.py:1: PerformanceWarning: Resolving the schema of a LazyFrame is a potentially expensive operation. Use `LazyFrame.collect_schema()` to get the schema without this warning.\n",
      "  cat_cols = [name for name, dtype in ref_data_v2.schema.items() if dtype == pl.Utf8]\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [name for name, dtype in ref_data_v2.schema.items() if dtype == pl.Utf8]\n",
    "\n",
    "# Lazy ile category (Polars'ta Categorical) dönüşümü\n",
    "ref_data_v2 = ref_data_v2.with_columns([\n",
    "    pl.col(col).cast(pl.Categorical) for col in cat_cols\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:12:36.674666Z",
     "iopub.status.busy": "2025-10-19T17:12:36.674185Z",
     "iopub.status.idle": "2025-10-19T17:12:36.678092Z",
     "shell.execute_reply": "2025-10-19T17:12:36.677316Z",
     "shell.execute_reply.started": "2025-10-19T17:12:36.674642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ref_data_v3 = ref_data_v2\n",
    "ref_data_v4 = ref_data_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:12:43.033682Z",
     "iopub.status.busy": "2025-10-19T17:12:43.033142Z",
     "iopub.status.idle": "2025-10-19T17:12:43.098221Z",
     "shell.execute_reply": "2025-10-19T17:12:43.097638Z",
     "shell.execute_reply.started": "2025-10-19T17:12:43.033658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ref_data_v4 = ref_data_v4.collect().lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T17:12:46.943014Z",
     "iopub.status.busy": "2025-10-19T17:12:46.942751Z",
     "iopub.status.idle": "2025-10-19T17:12:58.288017Z",
     "shell.execute_reply": "2025-10-19T17:12:58.287272Z",
     "shell.execute_reply.started": "2025-10-19T17:12:46.942995Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing last 1 month(s)\n",
      "Processing last 3 month(s)\n",
      "Processing last 6 month(s)\n",
      "Processing last 9 month(s)\n",
      "Processing last 12 month(s)\n",
      "Part 1 completed: Monthly sum, mean, min, max features added (with ratios)\n",
      "Processing average, min, max features for last 1 month(s)\n",
      "Processing average, min, max features for last 3 month(s)\n",
      "Processing average, min, max features for last 6 month(s)\n",
      "Processing average, min, max features for last 9 month(s)\n",
      "Processing average, min, max features for last 12 month(s)\n",
      "Part 2 completed: Average, min, max amount features added (with ratios)\n",
      "\n",
      "Volatility hesaplama başlıyor...\n",
      "\n",
      "\n",
      "Processing metrics for last 1 month(s)...\n",
      "\n",
      "Calculating rank features for last 1 month(s)...\n",
      "\n",
      "Processing metrics for last 3 month(s)...\n",
      "\n",
      "Calculating rank features for last 3 month(s)...\n",
      "\n",
      "Processing metrics for last 6 month(s)...\n",
      "\n",
      "Calculating rank features for last 6 month(s)...\n",
      "\n",
      "Processing metrics for last 9 month(s)...\n",
      "\n",
      "Calculating rank features for last 9 month(s)...\n",
      "\n",
      "Processing metrics for last 12 month(s)...\n",
      "\n",
      "Calculating rank features for last 12 month(s)...\n",
      "Part 3 completed: Volatility features added\n",
      "\n",
      "Ek feature hesaplamaları başlıyor...\n",
      "\n",
      "Part 4 completed: Trend and spike features added\n",
      "Part 5 completed: Rolling skew, kurtosis, and z-score features added\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "\n",
    "# =========================================================================\n",
    "# CRITICAL FIX: Parse date column at the very beginning\n",
    "# =========================================================================\n",
    "customer_history = customer_history.with_columns(\n",
    "    pl.col('date').str.strptime(pl.Date, format='%Y-%m-%d').alias('date')\n",
    ")\n",
    "\n",
    "# =========================================================================\n",
    "# PART 1: MONTHLY SUM, MEAN, MIN, MAX FEATURES\n",
    "# =========================================================================\n",
    "month_windows = [1,3, 6, 9, 12]\n",
    "numeric_cols = ['mobile_eft_all_cnt', 'mobile_eft_all_amt', 'cc_transaction_all_amt', 'cc_transaction_all_cnt', 'active_product_category_nbr']\n",
    "\n",
    "# Başlangıç LazyFrame\n",
    "customer_last_feats_month = (\n",
    "    customer_history\n",
    "    .select(pl.col('cust_id').unique())\n",
    ")\n",
    "\n",
    "# Her müşteri için son tarih\n",
    "last_dates = (\n",
    "    customer_history\n",
    "    .group_by('cust_id')\n",
    "    .agg(pl.col('date').max().alias('last_date'))\n",
    ")\n",
    "\n",
    "# Son tarihi müşteri geçmişine ekle\n",
    "customer_history_with_last = customer_history.join(last_dates, on='cust_id', how='left')\n",
    "\n",
    "# Her zaman penceresi için feature üret\n",
    "for m in month_windows:\n",
    "    print(f\"Processing last {m} month(s)\")\n",
    "    \n",
    "    temp = (\n",
    "        customer_history_with_last\n",
    "        .filter(pl.col('date') >= pl.col('last_date').dt.offset_by(f'-{m}mo'))\n",
    "    )\n",
    "    \n",
    "    sum_exprs = [pl.col(col).sum().alias(f\"{col}_last_{m}m_sum\") for col in numeric_cols]\n",
    "    mean_exprs = [pl.col(col).mean().alias(f\"{col}_last_{m}m_mean\") for col in numeric_cols]\n",
    "    min_exprs = [pl.col(col).min().alias(f\"{col}_last_{m}m_min\") for col in numeric_cols]\n",
    "    max_exprs = [pl.col(col).max().alias(f\"{col}_last_{m}m_max\") for col in numeric_cols]\n",
    "    \n",
    "    temp_agg = temp.group_by('cust_id').agg(sum_exprs + mean_exprs + min_exprs + max_exprs)\n",
    "    \n",
    "    customer_last_feats_month = (\n",
    "        customer_last_feats_month\n",
    "        .join(temp_agg, on='cust_id', how='left')\n",
    "    )\n",
    "\n",
    "# --- SUM & MEAN RATIO FEATURES ---\n",
    "ratio_exprs = []\n",
    "for col in numeric_cols:\n",
    "    for i in range(len(month_windows)):\n",
    "        for j in range(i + 1, len(month_windows)):\n",
    "            w1, w2 = month_windows[i], month_windows[j]\n",
    "            ratio_exprs.extend([\n",
    "                (pl.col(f\"{col}_last_{w1}m_sum\") / (pl.col(f\"{col}_last_{w2}m_sum\") + 1e-6))\n",
    "                .alias(f\"{col}_sum_ratio_{w1}_{w2}_m\"),\n",
    "                (pl.col(f\"{col}_last_{w1}m_mean\") / (pl.col(f\"{col}_last_{w2}m_mean\") + 1e-6))\n",
    "                .alias(f\"{col}_mean_ratio_{w1}_{w2}_m\"),\n",
    "                (pl.col(f\"{col}_last_{w1}m_min\") / (pl.col(f\"{col}_last_{w2}m_min\") + 1e-6))\n",
    "                .alias(f\"{col}_min_ratio_{w1}_{w2}_m\"),\n",
    "                (pl.col(f\"{col}_last_{w1}m_max\") / (pl.col(f\"{col}_last_{w2}m_max\") + 1e-6))\n",
    "                .alias(f\"{col}_max_ratio_{w1}_{w2}_m\")\n",
    "            ])\n",
    "customer_last_feats_month = customer_last_feats_month.with_columns(ratio_exprs)\n",
    "\n",
    "# Ref data ile birleştir\n",
    "ref_data_v5 = ref_data_v4.join(customer_last_feats_month, on='cust_id', how='left')\n",
    "print(\"Part 1 completed: Monthly sum, mean, min, max features added (with ratios)\")\n",
    "\n",
    "# =========================================================================\n",
    "# PART 2: AVERAGE, MIN, MAX FEATURES (mobile_eft_avg_amt, cc_transaction_avg_amt)\n",
    "# =========================================================================\n",
    "month_windows = [1,3, 6, 9, 12]\n",
    "numeric_cols = ['mobile_eft_all_cnt', 'mobile_eft_all_amt', \n",
    "                'cc_transaction_all_amt', 'cc_transaction_all_cnt']\n",
    "\n",
    "customer_avg_feats = customer_history.select(pl.col('cust_id').unique())\n",
    "\n",
    "for m in month_windows:\n",
    "    print(f\"Processing average, min, max features for last {m} month(s)\")\n",
    "    \n",
    "    temp = (\n",
    "        customer_history_with_last\n",
    "        .filter(pl.col('date') >= pl.col('last_date').dt.offset_by(f'-{m}mo'))\n",
    "    )\n",
    "    \n",
    "    temp_agg = (\n",
    "        temp\n",
    "        .group_by('cust_id')\n",
    "        .agg([\n",
    "            pl.col('mobile_eft_all_amt').sum().alias('mobile_eft_all_amt_sum'),\n",
    "            pl.col('mobile_eft_all_cnt').sum().alias('mobile_eft_all_cnt_sum'),\n",
    "            pl.col('cc_transaction_all_amt').sum().alias('cc_transaction_all_amt_sum'),\n",
    "            pl.col('cc_transaction_all_cnt').sum().alias('cc_transaction_all_cnt_sum'),\n",
    "            pl.col('mobile_eft_all_amt').min().alias('mobile_eft_all_amt_min'),\n",
    "            pl.col('mobile_eft_all_amt').max().alias('mobile_eft_all_amt_max'),\n",
    "            pl.col('cc_transaction_all_amt').min().alias('cc_transaction_all_amt_min'),\n",
    "            pl.col('cc_transaction_all_amt').max().alias('cc_transaction_all_amt_max'),\n",
    "        ])\n",
    "        .with_columns([\n",
    "            # Average amount features\n",
    "            (pl.col('mobile_eft_all_amt_sum') / pl.col('mobile_eft_all_cnt_sum'))\n",
    "            .fill_nan(0).fill_null(0)\n",
    "            .alias(f'mobile_eft_avg_amt_last_{m}m'),\n",
    "            \n",
    "            (pl.col('cc_transaction_all_amt_sum') / pl.col('cc_transaction_all_cnt_sum'))\n",
    "            .fill_nan(0).fill_null(0)\n",
    "            .alias(f'cc_transaction_avg_amt_last_{m}m'),\n",
    "            \n",
    "            # Min/Max features\n",
    "            pl.col('mobile_eft_all_amt_min').alias(f'mobile_eft_amt_min_last_{m}m'),\n",
    "            pl.col('mobile_eft_all_amt_max').alias(f'mobile_eft_amt_max_last_{m}m'),\n",
    "            pl.col('cc_transaction_all_amt_min').alias(f'cc_transaction_amt_min_last_{m}m'),\n",
    "            pl.col('cc_transaction_all_amt_max').alias(f'cc_transaction_amt_max_last_{m}m'),\n",
    "        ])\n",
    "        .select([\n",
    "            'cust_id', \n",
    "            f'mobile_eft_avg_amt_last_{m}m', \n",
    "            f'cc_transaction_avg_amt_last_{m}m',\n",
    "            f'mobile_eft_amt_min_last_{m}m',\n",
    "            f'mobile_eft_amt_max_last_{m}m',\n",
    "            f'cc_transaction_amt_min_last_{m}m',\n",
    "            f'cc_transaction_amt_max_last_{m}m'\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    customer_avg_feats = customer_avg_feats.join(temp_agg, on='cust_id', how='left')\n",
    "\n",
    "# --- AVG, MIN, MAX RATIO FEATURES ---\n",
    "avg_ratio_exprs = []\n",
    "eft_avg_cols = [f\"mobile_eft_avg_amt_last_{m}m\" for m in month_windows]\n",
    "cc_avg_cols = [f\"cc_transaction_avg_amt_last_{m}m\" for m in month_windows]\n",
    "eft_min_cols = [f\"mobile_eft_amt_min_last_{m}m\" for m in month_windows]\n",
    "eft_max_cols = [f\"mobile_eft_amt_max_last_{m}m\" for m in month_windows]\n",
    "cc_min_cols = [f\"cc_transaction_amt_min_last_{m}m\" for m in month_windows]\n",
    "cc_max_cols = [f\"cc_transaction_amt_max_last_{m}m\" for m in month_windows]\n",
    "\n",
    "for i in range(len(month_windows)):\n",
    "    for j in range(i + 1, len(month_windows)):\n",
    "        w1, w2 = month_windows[i], month_windows[j]\n",
    "        avg_ratio_exprs.extend([\n",
    "            # Average ratios\n",
    "            (pl.col(f\"mobile_eft_avg_amt_last_{w1}m\") / (pl.col(f\"mobile_eft_avg_amt_last_{w2}m\") + 1e-6))\n",
    "            .alias(f\"mobile_eft_avg_ratio_{w1}_{w2}_m\"),\n",
    "            (pl.col(f\"cc_transaction_avg_amt_last_{w1}m\") / (pl.col(f\"cc_transaction_avg_amt_last_{w2}m\") + 1e-6))\n",
    "            .alias(f\"cc_transaction_avg_ratio_{w1}_{w2}_m\"),\n",
    "            \n",
    "            # Min ratios\n",
    "            (pl.col(f\"mobile_eft_amt_min_last_{w1}m\") / (pl.col(f\"mobile_eft_amt_min_last_{w2}m\") + 1e-6))\n",
    "            .alias(f\"mobile_eft_min_ratio_{w1}_{w2}_m\"),\n",
    "            (pl.col(f\"cc_transaction_amt_min_last_{w1}m\") / (pl.col(f\"cc_transaction_amt_min_last_{w2}m\") + 1e-6))\n",
    "            .alias(f\"cc_transaction_min_ratio_{w1}_{w2}_m\"),\n",
    "            \n",
    "            # Max ratios\n",
    "            (pl.col(f\"mobile_eft_amt_max_last_{w1}m\") / (pl.col(f\"mobile_eft_amt_max_last_{w2}m\") + 1e-6))\n",
    "            .alias(f\"mobile_eft_max_ratio_{w1}_{w2}_m\"),\n",
    "            (pl.col(f\"cc_transaction_amt_max_last_{w1}m\") / (pl.col(f\"cc_transaction_amt_max_last_{w2}m\") + 1e-6))\n",
    "            .alias(f\"cc_transaction_max_ratio_{w1}_{w2}_m\"),\n",
    "        ])\n",
    "customer_avg_feats = customer_avg_feats.with_columns(avg_ratio_exprs)\n",
    "\n",
    "# Ref data merge\n",
    "ref_data_v6 = ref_data_v5.join(customer_avg_feats, on='cust_id', how='left')\n",
    "ref_data_v6 = ref_data_v6.collect().lazy()\n",
    "\n",
    "print(\"Part 2 completed: Average, min, max amount features added (with ratios)\")\n",
    "\n",
    "# =========================================================================\n",
    "# PART 3: VOLATILITY FEATURES (Monthly Aggregated)\n",
    "# =========================================================================\n",
    "print(\"\\nVolatility hesaplama başlıyor...\\n\")\n",
    "\n",
    "month_windows = [1, 3, 6, 9, 12]\n",
    "numeric_cols = ['mobile_eft_all_cnt', 'mobile_eft_all_amt', \n",
    "                'cc_transaction_all_amt', 'cc_transaction_all_cnt']\n",
    "\n",
    "# Aylık bazda toplama\n",
    "monthly = (\n",
    "    customer_history\n",
    "    .with_columns(\n",
    "        pl.col('date').dt.truncate('1mo').alias('year_month')\n",
    "    )\n",
    "    .group_by(['cust_id', 'year_month'])\n",
    "    .agg([pl.col(col).sum() for col in numeric_cols])\n",
    ")\n",
    "\n",
    "# Son tarihleri ekle\n",
    "monthly = monthly.join(last_dates, on='cust_id', how='left')\n",
    "\n",
    "# Boş LazyFrame\n",
    "customer_vol_feats = monthly.select(pl.col('cust_id').unique())\n",
    "\n",
    "for m in month_windows:\n",
    "    print(f\"\\nProcessing metrics for last {m} month(s)...\\n\")\n",
    "    \n",
    "    temp = (\n",
    "        monthly\n",
    "        .filter(pl.col('year_month') >= pl.col('last_date').dt.offset_by(f'-{m}mo'))\n",
    "        .sort(['cust_id', 'year_month'])\n",
    "    )\n",
    "    \n",
    "    # STD (Volatility)\n",
    "    std_exprs = [\n",
    "        pl.col(col).std().alias(f\"{col}_std_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_std = temp.group_by('cust_id').agg(std_exprs)\n",
    "    \n",
    "    # Window-adjusted Volatility\n",
    "    vol_exprs = [\n",
    "        (pl.col(f\"{col}_std_last_{m}m\") * np.sqrt(m)).alias(f\"{col}_vol_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_vol = temp_std.select(['cust_id'] + vol_exprs)\n",
    "    \n",
    "    # EMA\n",
    "    ema_exprs = [\n",
    "        pl.col(col).ewm_mean(span=m, min_samples=1).last().alias(f\"{col}_ema_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_ema = temp.group_by('cust_id').agg(ema_exprs)\n",
    "    \n",
    "    # DELTA (Son - Önceki)\n",
    "    delta_exprs = [\n",
    "        pl.when(pl.col(col).len() > 1)\n",
    "        .then(pl.col(col).last() - pl.col(col).slice(-2, 1).first())\n",
    "        .otherwise(0)\n",
    "        .alias(f\"{col}_delta_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_delta = temp.group_by('cust_id').agg(delta_exprs)\n",
    "    \n",
    "    # GROWTH RATE\n",
    "    growth_exprs = [\n",
    "        pl.when(pl.col(col).len() > 1)\n",
    "        .then(\n",
    "            (pl.col(col).last() / \n",
    "             pl.when(pl.col(col).slice(-2, 1).first() == 0)\n",
    "             .then(pl.lit(None))\n",
    "             .otherwise(pl.col(col).slice(-2, 1).first()) - 1)\n",
    "            .fill_null(0)\n",
    "        )\n",
    "        .otherwise(0)\n",
    "        .alias(f\"{col}_growth_rate_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_growth = temp.group_by('cust_id').agg(growth_exprs)\n",
    "    \n",
    "    # TREND DIRECTION\n",
    "    trend_exprs = [\n",
    "        pl.when(pl.col(col).ewm_mean(span=3, min_samples=1).len() > 1)\n",
    "        .then(\n",
    "            pl.when(\n",
    "                pl.col(col).ewm_mean(span=3, min_samples=1).last() - \n",
    "                pl.col(col).ewm_mean(span=3, min_samples=1).first() > 0\n",
    "            )\n",
    "            .then(1)\n",
    "            .when(\n",
    "                pl.col(col).ewm_mean(span=3, min_samples=1).last() - \n",
    "                pl.col(col).ewm_mean(span=3, min_samples=1).first() < 0\n",
    "            )\n",
    "            .then(-1)\n",
    "            .otherwise(0)\n",
    "        )\n",
    "        .otherwise(0)\n",
    "        .alias(f\"{col}_trend_dir_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_trend = temp.group_by('cust_id').agg(trend_exprs)\n",
    "    \n",
    "    # VA (Volatility Adjusted) = std / mean\n",
    "    mean_exprs_for_va = [\n",
    "        pl.col(col).mean().alias(f\"{col}_mean_temp\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_mean = temp.group_by('cust_id').agg(mean_exprs_for_va)\n",
    "    \n",
    "    va_exprs = [\n",
    "        (pl.col(f\"{col}_std_last_{m}m\") / pl.col(f\"{col}_mean_temp\"))\n",
    "        .alias(f\"{col}_va_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_va = (\n",
    "        temp_std\n",
    "        .join(temp_mean, on='cust_id', how='left')\n",
    "        .select(['cust_id'] + va_exprs)\n",
    "    )\n",
    "    \n",
    "    # VS (Volatility Stability) window=2\n",
    "    vs_2_exprs = [\n",
    "        (pl.col(col).rolling_std(window_size=2).diff().last().fill_null(0))\n",
    "        .alias(f\"{col}_vs_2_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_vs_2 = temp.group_by('cust_id').agg(vs_2_exprs)\n",
    "    \n",
    "    # VS (Volatility Stability) window=3\n",
    "    vs_3_exprs = [\n",
    "        (pl.col(col).rolling_std(window_size=3).diff().last().fill_null(0))\n",
    "        .alias(f\"{col}_vs_3_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_vs_3 = temp.group_by('cust_id').agg(vs_3_exprs)\n",
    "    \n",
    "    # RANK (Percentile Rank)\n",
    "    print(f\"Calculating rank features for last {m} month(s)...\")\n",
    "    \n",
    "    rank_cols_exprs = [\n",
    "        (pl.col(col).rank(method='average').over('year_month') / pl.col(col).count().over('year_month'))\n",
    "        .alias(f\"{col}_rank_pct\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    \n",
    "    temp_rank = temp.with_columns(rank_cols_exprs)\n",
    "    \n",
    "    rank_mean_exprs = [\n",
    "        pl.col(f\"{col}_rank_pct\").tail(m).mean().alias(f\"{col}_rank_pct_mean_last_{m}m\")\n",
    "        for col in numeric_cols\n",
    "    ]\n",
    "    temp_rank_mean = temp_rank.group_by('cust_id').agg(rank_mean_exprs)\n",
    "    \n",
    "    # Merge all metrics\n",
    "    customer_vol_feats = (\n",
    "        customer_vol_feats\n",
    "        .join(temp_std, on='cust_id', how='left')\n",
    "        .join(temp_vol, on='cust_id', how='left')\n",
    "        .join(temp_ema, on='cust_id', how='left')\n",
    "        .join(temp_delta, on='cust_id', how='left')\n",
    "        .join(temp_growth, on='cust_id', how='left')\n",
    "        .join(temp_trend, on='cust_id', how='left')\n",
    "        .join(temp_va, on='cust_id', how='left')\n",
    "        .join(temp_vs_2, on='cust_id', how='left')\n",
    "        .join(temp_vs_3, on='cust_id', how='left')\n",
    "        .join(temp_rank_mean, on='cust_id', how='left')\n",
    "    )\n",
    "\n",
    "# Final merge\n",
    "ref_data_v7 = ref_data_v6.join(customer_vol_feats, on='cust_id', how='left')\n",
    "\n",
    "print(\"Part 3 completed: Volatility features added\")\n",
    "\n",
    "\n",
    "print(\"\\nEk feature hesaplamaları başlıyor...\\n\")\n",
    "\n",
    "# Boş container - sadece cust_id\n",
    "customer_extra_feats = ref_data_v7.select(pl.col('cust_id').unique())\n",
    "\n",
    "# TREND / FARK FEATURES - Using available columns from Parts 1-3\n",
    "month_windows = [1, 3, 6, 9, 12]\n",
    "trend_feats_list = []\n",
    "\n",
    "for w in month_windows:\n",
    "    # Önceki pencereler için window seçimi\n",
    "    short_w = w\n",
    "    # Sadece mevcut month_windows içinden bir sonraki window'u seç\n",
    "    available_longer_windows = [mo for mo in month_windows if mo > w]\n",
    "    if not available_longer_windows:\n",
    "        continue  # Son window için karşılaştırma yapma\n",
    "    long_w = available_longer_windows[0]  # İlk büyük window'u al\n",
    "\n",
    "    temp_feats = (\n",
    "        ref_data_v7\n",
    "        .select([\n",
    "            'cust_id',\n",
    "            f'cc_transaction_all_amt_last_{short_w}m_sum',\n",
    "            f'cc_transaction_all_amt_last_{long_w}m_mean',\n",
    "            f'mobile_eft_all_cnt_last_{short_w}m_sum',\n",
    "            f'mobile_eft_all_cnt_last_{long_w}m_mean'\n",
    "        ])\n",
    "        .with_columns([\n",
    "            # Fark\n",
    "            (pl.col(f'cc_transaction_all_amt_last_{short_w}m_sum') - \n",
    "             pl.col(f'cc_transaction_all_amt_last_{long_w}m_mean'))\n",
    "            .alias(f'cc_transaction_amt_short{short_w}_vs_long{long_w}_diff'),\n",
    "\n",
    "            # Oran\n",
    "            (pl.col(f'mobile_eft_all_cnt_last_{short_w}m_sum') / \n",
    "             (pl.col(f'mobile_eft_all_cnt_last_{long_w}m_mean') + 1e-6))\n",
    "            .alias(f'mobile_eft_cnt_short{short_w}_vs_long{long_w}_ratio')\n",
    "        ])\n",
    "        .select(['cust_id', f'cc_transaction_amt_short{short_w}_vs_long{long_w}_diff',\n",
    "                 f'mobile_eft_cnt_short{short_w}_vs_long{long_w}_ratio'])\n",
    "    )\n",
    "    trend_feats_list.append(temp_feats)\n",
    "\n",
    "# Tüm trend features'ları birleştir\n",
    "from functools import reduce\n",
    "customer_trend_feats = reduce(lambda left, right: left.join(right, on='cust_id', how='left'), trend_feats_list)\n",
    "\n",
    "# Final merge\n",
    "ref_data_v8 = ref_data_v7.join(customer_trend_feats, on='cust_id', how='left')\n",
    "\n",
    "spike_feats_list = []\n",
    "\n",
    "for m in month_windows:\n",
    "    temp = (\n",
    "        monthly\n",
    "        .filter(pl.col('year_month') >= pl.col('last_date').dt.offset_by(f'-{m}mo'))\n",
    "        .sort(['cust_id', 'year_month'])\n",
    "    )\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        spike_count = (\n",
    "            (pl.col(col).diff().fill_null(0) > 0).sum().alias(f\"{col}_spike_count_last_{m}m\")\n",
    "        )\n",
    "\n",
    "        spike_maxabs = (\n",
    "            pl.col(col).diff().fill_null(0).abs().max().alias(f\"{col}_spike_maxabs_last_{m}m\")\n",
    "        )\n",
    "\n",
    "        temp_feats = temp.group_by('cust_id').agg([spike_count, spike_maxabs])\n",
    "        spike_feats_list.append(temp_feats)\n",
    "\n",
    "# Tüm spikeness features'ları birleştir\n",
    "from functools import reduce\n",
    "customer_spike_feats = reduce(lambda left, right: left.join(right, on='cust_id', how='left'), spike_feats_list)\n",
    "\n",
    "# Final merge\n",
    "ref_data_v9 = ref_data_v8.join(customer_spike_feats, on='cust_id', how='left')\n",
    "\n",
    "print(\"Part 4 completed: Trend and spike features added\")\n",
    "\n",
    "import polars as pl\n",
    "from functools import reduce\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "rolling_feats_list = []\n",
    "window_size = 3  # rolling window\n",
    "\n",
    "for m in month_windows:\n",
    "    temp = (\n",
    "        monthly\n",
    "        .filter(pl.col('year_month') >= pl.col('last_date').dt.offset_by(f'-{m}mo'))\n",
    "        .sort(['cust_id', 'year_month'])\n",
    "    )\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        # cust_id bazında liste halinde topla ve hepsini tek seferde hesapla\n",
    "        temp_feats = (\n",
    "            temp.group_by('cust_id')\n",
    "            .agg([\n",
    "                pl.col(col).alias(f\"{col}_list\")\n",
    "            ])\n",
    "            .with_columns([\n",
    "                # Skew\n",
    "                pl.col(f\"{col}_list\")\n",
    "                .map_elements(\n",
    "                    lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
    "                    return_dtype=pl.Float64\n",
    "                ).alias(f\"{col}_roll_skew_last_{m}m\"),\n",
    "                \n",
    "                # Kurtosis\n",
    "                pl.col(f\"{col}_list\")\n",
    "                .map_elements(\n",
    "                    lambda x: float(stats.kurtosis(x[-window_size:])) if len(x) >= window_size else 0,\n",
    "                    return_dtype=pl.Float64\n",
    "                ).alias(f\"{col}_roll_kurt_last_{m}m\"),\n",
    "                \n",
    "                # Z-Score\n",
    "                pl.col(f\"{col}_list\")\n",
    "                .map_elements(\n",
    "                    lambda x: (x[-1] - np.mean(x)) / (np.std(x) + 1e-6) if len(x) >= 1 else 0,\n",
    "                    return_dtype=pl.Float64\n",
    "                ).alias(f\"{col}_zscore_last_{m}m\")\n",
    "            ])\n",
    "            .drop(f\"{col}_list\")\n",
    "            .select(['cust_id', f\"{col}_roll_skew_last_{m}m\", f\"{col}_roll_kurt_last_{m}m\", f\"{col}_zscore_last_{m}m\"])\n",
    "        )\n",
    "        \n",
    "        rolling_feats_list.append(temp_feats)\n",
    "\n",
    "# Tüm rolling feature'ları birleştir (hepsi lazy)\n",
    "customer_rolling_feats = reduce(lambda left, right: left.join(right, on='cust_id', how='left'), rolling_feats_list)\n",
    "\n",
    "# Final merge (burada da lazy kalır, ref_data_v10 ne ise ona göre)\n",
    "ref_data_v11 = ref_data_v9.join(customer_rolling_feats, on='cust_id', how='left')\n",
    "print(\"Part 5 completed: Rolling skew, kurtosis, and z-score features added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-19T17:30:13.865Z",
     "iopub.execute_input": "2025-10-19T17:12:58.289505Z",
     "iopub.status.busy": "2025-10-19T17:12:58.289249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:463: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.kurtosis(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:456: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.skew(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:463: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.kurtosis(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:463: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.kurtosis(x[-window_size:])) if len(x) >= window_size else 0,\n",
      "/tmp/ipykernel_37/362678968.py:463: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  lambda x: float(stats.kurtosis(x[-window_size:])) if len(x) >= window_size else 0,\n"
     ]
    }
   ],
   "source": [
    "df=ref_data_v11.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-19T17:30:13.865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================================================================\n",
    "# UYARIYA SEBEP OLAN FEATURE'LARI TESPİT ET\n",
    "# =========================================================================\n",
    "\n",
    "def detect_problematic_features(df):\n",
    "    \"\"\"\n",
    "    Skewness ve Kurtosis uyarılarına sebep olan feature'ları tespit eder\n",
    "    \"\"\"\n",
    "    \n",
    "    # Skew ve Kurtosis feature'larını bul\n",
    "    skew_cols = [col for col in df.columns if '_roll_skew_last_' in col]\n",
    "    kurt_cols = [col for col in df.columns if '_roll_kurt_last_' in col]\n",
    "    zscore_cols = [col for col in df.columns if '_zscore_last_' in col]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"PROBLEMATIC FEATURE DETECTION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # DataFrame'i collect et (eğer lazy ise)\n",
    "    if isinstance(df, pl.LazyFrame):\n",
    "        df = df.collect()\n",
    "    \n",
    "    results = {\n",
    "        'feature': [],\n",
    "        'null_count': [],\n",
    "        'inf_count': [],\n",
    "        'zero_count': [],\n",
    "        'unique_values': [],\n",
    "        'mean': [],\n",
    "        'std': [],\n",
    "        'min': [],\n",
    "        'max': [],\n",
    "        'issue_type': []\n",
    "    }\n",
    "    \n",
    "    all_problem_cols = skew_cols + kurt_cols + zscore_cols\n",
    "    \n",
    "    for col in all_problem_cols:\n",
    "        data = df[col].to_numpy()\n",
    "        \n",
    "        null_cnt = np.sum(np.isnan(data))\n",
    "        inf_cnt = np.sum(np.isinf(data))\n",
    "        zero_cnt = np.sum(data == 0)\n",
    "        unique_vals = len(np.unique(data[~np.isnan(data)]))\n",
    "        \n",
    "        issue = []\n",
    "        \n",
    "        # Problemi tespit et\n",
    "        if null_cnt > len(data) * 0.5:\n",
    "            issue.append('HIGH_NULL')\n",
    "        if inf_cnt > 0:\n",
    "            issue.append('HAS_INF')\n",
    "        if zero_cnt > len(data) * 0.8:\n",
    "            issue.append('MOSTLY_ZERO')\n",
    "        if unique_vals < 5:\n",
    "            issue.append('LOW_VARIANCE')\n",
    "        \n",
    "        # İstatistikler\n",
    "        valid_data = data[~np.isnan(data) & ~np.isinf(data)]\n",
    "        \n",
    "        if len(valid_data) > 0:\n",
    "            results['feature'].append(col)\n",
    "            results['null_count'].append(null_cnt)\n",
    "            results['inf_count'].append(inf_cnt)\n",
    "            results['zero_count'].append(zero_cnt)\n",
    "            results['unique_values'].append(unique_vals)\n",
    "            results['mean'].append(np.mean(valid_data))\n",
    "            results['std'].append(np.std(valid_data))\n",
    "            results['min'].append(np.min(valid_data))\n",
    "            results['max'].append(np.max(valid_data))\n",
    "            results['issue_type'].append(','.join(issue) if issue else 'OK')\n",
    "    \n",
    "    # Pandas DataFrame olarak döndür\n",
    "    report = pd.DataFrame(results)\n",
    "    \n",
    "    # Sadece problemli olanları filtrele\n",
    "    problematic = report[report['issue_type'] != 'OK']\n",
    "    \n",
    "    print(f\"\\nTotal Features Analyzed: {len(all_problem_cols)}\")\n",
    "    print(f\"Problematic Features Found: {len(problematic)}\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    if len(problematic) > 0:\n",
    "        print(\"\\nPROBLEMATIC FEATURES:\")\n",
    "        print(problematic.to_string())\n",
    "    else:\n",
    "        print(\"\\n✅ No problematic features found!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FEATURE STATISTICS SUMMARY:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Kategori bazında özet\n",
    "    for category in ['skew', 'kurt', 'zscore']:\n",
    "        cat_cols = [col for col in all_problem_cols if category in col]\n",
    "        cat_data = report[report['feature'].str.contains(category)]\n",
    "        \n",
    "        print(f\"\\n{category.upper()} Features ({len(cat_cols)} total):\")\n",
    "        print(f\"  - Mean null count: {cat_data['null_count'].mean():.1f}\")\n",
    "        print(f\"  - Mean zero count: {cat_data['zero_count'].mean():.1f}\")\n",
    "        print(f\"  - Mean unique values: {cat_data['unique_values'].mean():.1f}\")\n",
    "        print(f\"  - Issues: {cat_data[cat_data['issue_type'] != 'OK'].shape[0]} features\")\n",
    "    \n",
    "    return report, problematic\n",
    "\n",
    "\n",
    "def check_identical_values(df, numeric_cols=['mobile_eft_all_cnt', 'mobile_eft_all_amt', \n",
    "                                              'cc_transaction_all_amt', 'cc_transaction_all_cnt']):\n",
    "    \"\"\"\n",
    "    Aylık verilerde aynı değerlere sahip müşterileri bulur (uyarının asıl sebebi)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"IDENTICAL VALUE DETECTION (Root Cause of Warnings)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if isinstance(df, pl.LazyFrame):\n",
    "        df = df.collect()\n",
    "    \n",
    "    # Her müşteri için aylık varyasyonu kontrol et\n",
    "    results = []\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        # Eğer aylık aggregated data varsa\n",
    "        if 'monthly' in globals():\n",
    "            monthly_df = globals()['monthly']\n",
    "            if isinstance(monthly_df, pl.LazyFrame):\n",
    "                monthly_df = monthly_df.collect()\n",
    "            \n",
    "            # Her müşteri için std hesapla\n",
    "            variance_check = (\n",
    "                monthly_df\n",
    "                .group_by('cust_id')\n",
    "                .agg([\n",
    "                    pl.col(col).std().alias(f'{col}_std'),\n",
    "                    pl.col(col).count().alias(f'{col}_count')\n",
    "                ])\n",
    "                .with_columns([\n",
    "                    (pl.col(f'{col}_std') < 1e-10).alias(f'{col}_identical')\n",
    "                ])\n",
    "            )\n",
    "            \n",
    "            identical_count = variance_check.filter(pl.col(f'{col}_identical'))[f'{col}_identical'].sum()\n",
    "            total_customers = variance_check.shape[0]\n",
    "            \n",
    "            results.append({\n",
    "                'column': col,\n",
    "                'customers_with_identical_values': identical_count,\n",
    "                'total_customers': total_customers,\n",
    "                'percentage': f\"{(identical_count/total_customers*100):.2f}%\"\n",
    "            })\n",
    "    \n",
    "    if results:\n",
    "        result_df = pd.DataFrame(results)\n",
    "        print(\"\\nCustomers with Identical Monthly Values:\")\n",
    "        print(result_df.to_string(index=False))\n",
    "        print(\"\\n⚠️  These customers cause 'catastrophic cancellation' warnings\")\n",
    "        print(\"   because skew/kurtosis cannot be calculated for constant values.\")\n",
    "    \n",
    "    return result_df if results else None\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# KULLANIM\n",
    "# =========================================================================\n",
    "\n",
    "# 1. Problemli feature'ları tespit et\n",
    "report, problematic = detect_problematic_features(ref_data_v11)\n",
    "\n",
    "# 2. Aynı değerlere sahip müşterileri tespit et (uyarının asıl sebebi)\n",
    "if 'monthly' in globals():\n",
    "    identical_report = check_identical_values(ref_data_v11)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T07:18:26.838089Z",
     "iopub.status.busy": "2025-10-19T07:18:26.837721Z",
     "iopub.status.idle": "2025-10-19T07:18:37.530338Z",
     "shell.execute_reply": "2025-10-19T07:18:37.529135Z",
     "shell.execute_reply.started": "2025-10-19T07:18:26.838059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.write_parquet(\"ref_data_v8_last_11.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T07:18:53.006298Z",
     "iopub.status.busy": "2025-10-19T07:18:53.005992Z",
     "iopub.status.idle": "2025-10-19T07:18:53.025655Z",
     "shell.execute_reply": "2025-10-19T07:18:53.024558Z",
     "shell.execute_reply.started": "2025-10-19T07:18:53.006279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "kaggle_file = \"/kaggle/input/kagglejson/kaggle (2).json\"\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "shutil.copy(kaggle_file, os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n",
    "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T14:05:27.776760Z",
     "iopub.status.busy": "2025-10-19T14:05:27.776094Z",
     "iopub.status.idle": "2025-10-19T14:05:33.747538Z",
     "shell.execute_reply": "2025-10-19T14:05:33.746732Z",
     "shell.execute_reply.started": "2025-10-19T14:05:27.776737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "ref_final = pl.read_parquet('/kaggle/input/datasetv8final/ref_data_v8_last_12.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T14:05:33.749580Z",
     "iopub.status.busy": "2025-10-19T14:05:33.749351Z",
     "iopub.status.idle": "2025-10-19T14:05:36.299104Z",
     "shell.execute_reply": "2025-10-19T14:05:36.298321Z",
     "shell.execute_reply.started": "2025-10-19T14:05:33.749562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DROP_COLS = ['cust_id','ref_date','split']\n",
    "train_ref_data = ref_final[ref_final['split'] == \"Train\"].drop(DROP_COLS,axis=1)\n",
    "test_ref_data = ref_final[ref_final['split'] == \"Test\"].drop(DROP_COLS + ['churn'],axis=1)\n",
    "train_ref_data[train_ref_data.select_dtypes(exclude=['object','category']).columns] = train_ref_data.select_dtypes(exclude=['object','category']).fillna(-9999)\n",
    "test_ref_data[test_ref_data.select_dtypes(exclude=['object','category']).columns] = test_ref_data.select_dtypes(exclude=['object','category']).fillna(-9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:43:58.061548Z",
     "iopub.status.busy": "2025-10-19T11:43:58.061249Z",
     "iopub.status.idle": "2025-10-19T12:33:14.496430Z",
     "shell.execute_reply": "2025-10-19T12:33:14.495593Z",
     "shell.execute_reply.started": "2025-10-19T11:43:58.061529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, EFeaturesSelectionAlgorithm, EShapCalcType\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "FEATURE_SELECTION = True\n",
    "\n",
    "if FEATURE_SELECTION:\n",
    "    summaries = []\n",
    "\n",
    "    # Eğitim verisi\n",
    "    X = train_ref_data.drop(columns=['churn', #'churn_2',\n",
    "                                     'split', 'date', \n",
    "                                     'cust_id'], \n",
    "                            errors=\"ignore\", axis=1)\n",
    "    y = train_ref_data['churn']\n",
    "\n",
    "    # Kategorik sütun isimleri\n",
    "    cat_idx = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    # StratifiedKFold tanımı\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, y_train = X.iloc[train_idx].copy(), y.iloc[train_idx].copy()\n",
    "        X_val,   y_val   = X.iloc[val_idx].copy(),   y.iloc[val_idx].copy()\n",
    "\n",
    "\n",
    "        params = {\n",
    "            'iterations': 1000,\n",
    "            'learning_rate': 0.05,\n",
    "            'depth': 6,\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'verbose': False,\n",
    "            'border_count': 256,\n",
    "            'task_type': 'GPU',\n",
    "            'auto_class_weights': \"Balanced\",\n",
    "            'boosting_type': \"Ordered\",\n",
    "            'use_best_model': False\n",
    "        }\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "\n",
    "        train_pool = Pool(X_train, y_train, cat_features=cat_idx)\n",
    "        val_pool   = Pool(X_val,   y_val,   cat_features=cat_idx)\n",
    "\n",
    "        summary = model.select_features(\n",
    "            train_pool,\n",
    "            eval_set=val_pool,\n",
    "            features_for_select=f'0-{X_train.shape[1]-1}',\n",
    "            num_features_to_select=50,\n",
    "            steps=5,\n",
    "            algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues,\n",
    "            shap_calc_type=EShapCalcType.Regular,\n",
    "            train_final_model=False,\n",
    "            logging_level='Silent',\n",
    "            plot=False  # Hız için False yapabilirsin\n",
    "        )\n",
    "        summaries.append(summary)\n",
    "\n",
    "    # Her fold için seçilen 25 özelliğin isim listelerini çıkar\n",
    "    selected_lists = [s[\"selected_features_names\"] for s in summaries]\n",
    "\n",
    "    # Tüm fold'lardaki seçimleri tek listeye açıp say\n",
    "    all_selected = [feat for sublist in selected_lists for feat in sublist]\n",
    "    counts = Counter(all_selected)\n",
    "\n",
    "    # 1+, 2+, 3+ listeleri (en az 1, 2, 3 defa ilk 25'e girenler)\n",
    "    top25_any   = sorted([f for f, c in counts.items() if c >= 1])\n",
    "    top25_2plus = sorted([f for f, c in counts.items() if c >= 2])\n",
    "    top25_3plus = sorted([f for f, c in counts.items() if c >= 3])\n",
    "\n",
    "    # Özet tablo\n",
    "    top25_summary_df = pd.DataFrame({\n",
    "        \"feature\": list(counts.keys()),\n",
    "        \"selected_in_folds\": list(counts.values())\n",
    "    }).sort_values(\"selected_in_folds\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T12:33:59.767916Z",
     "iopub.status.busy": "2025-10-19T12:33:59.767326Z",
     "iopub.status.idle": "2025-10-19T12:33:59.778137Z",
     "shell.execute_reply": "2025-10-19T12:33:59.777520Z",
     "shell.execute_reply.started": "2025-10-19T12:33:59.767895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "top25_summary_df.to_csv('top_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T15:00:33.290775Z",
     "iopub.status.busy": "2025-10-19T15:00:33.290242Z",
     "iopub.status.idle": "2025-10-19T15:00:33.306343Z",
     "shell.execute_reply": "2025-10-19T15:00:33.304536Z",
     "shell.execute_reply.started": "2025-10-19T15:00:33.290734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "top25_summary_df = pd.read_csv('/kaggle/working/top_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T15:00:38.091114Z",
     "iopub.status.busy": "2025-10-19T15:00:38.090642Z",
     "iopub.status.idle": "2025-10-19T15:00:38.110651Z",
     "shell.execute_reply": "2025-10-19T15:00:38.109610Z",
     "shell.execute_reply.started": "2025-10-19T15:00:38.091082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features = top25_summary_df.query('selected_in_folds >= 2').feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T15:00:54.347398Z",
     "iopub.status.busy": "2025-10-19T15:00:54.346827Z",
     "iopub.status.idle": "2025-10-19T15:54:47.035624Z",
     "shell.execute_reply": "2025-10-19T15:54:47.034672Z",
     "shell.execute_reply.started": "2025-10-19T15:00:54.347376Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-19 15:52:36</td></tr>\n",
       "<tr><td>Running for: </td><td>00:15:55.98        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.9/31.4 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=9<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 1.1683345372699212<br>Logical resource usage: 4.0/4 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_2235c263</td><td>TERMINATED</td><td>172.19.2.2:8336 </td><td style=\"text-align: right;\">          0.901514</td><td style=\"text-align: right;\">     0.0102229 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.937309</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        14.4091 </td><td style=\"text-align: right;\">1.16577</td></tr>\n",
       "<tr><td>train_model_c300a264</td><td>TERMINATED</td><td>172.19.2.2:8421 </td><td style=\"text-align: right;\">          0.665897</td><td style=\"text-align: right;\">     0.0442343 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.953045</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        17.2587 </td><td style=\"text-align: right;\">1.16375</td></tr>\n",
       "<tr><td>train_model_67fa5156</td><td>TERMINATED</td><td>172.19.2.2:8506 </td><td style=\"text-align: right;\">          0.861552</td><td style=\"text-align: right;\">     0.078248  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          1000</td><td style=\"text-align: right;\">   0.616479</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.9582 </td><td style=\"text-align: right;\">1.1664 </td></tr>\n",
       "<tr><td>train_model_743bdf6a</td><td>TERMINATED</td><td>172.19.2.2:8592 </td><td style=\"text-align: right;\">          0.909598</td><td style=\"text-align: right;\">     0.00794963</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          2000</td><td style=\"text-align: right;\">   0.821795</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        36.8506 </td><td style=\"text-align: right;\">1.17051</td></tr>\n",
       "<tr><td>train_model_8838ca6a</td><td>TERMINATED</td><td>172.19.2.2:8681 </td><td style=\"text-align: right;\">          0.717821</td><td style=\"text-align: right;\">     0.0227352 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">          1000</td><td style=\"text-align: right;\">   0.962478</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        21.0546 </td><td style=\"text-align: right;\">1.17081</td></tr>\n",
       "<tr><td>train_model_832e4045</td><td>TERMINATED</td><td>172.19.2.2:8767 </td><td style=\"text-align: right;\">          0.743082</td><td style=\"text-align: right;\">     0.0114851 </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.672078</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        27.8258 </td><td style=\"text-align: right;\">1.17524</td></tr>\n",
       "<tr><td>train_model_84cb03bb</td><td>TERMINATED</td><td>172.19.2.2:8853 </td><td style=\"text-align: right;\">          0.604909</td><td style=\"text-align: right;\">     0.022091  </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.974003</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        22.137  </td><td style=\"text-align: right;\">1.16448</td></tr>\n",
       "<tr><td>train_model_5d71ed4e</td><td>TERMINATED</td><td>172.19.2.2:8939 </td><td style=\"text-align: right;\">          0.804045</td><td style=\"text-align: right;\">     0.0456596 </td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.958218</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        22.8452 </td><td style=\"text-align: right;\">1.15757</td></tr>\n",
       "<tr><td>train_model_87663be4</td><td>TERMINATED</td><td>172.19.2.2:9025 </td><td style=\"text-align: right;\">          0.715009</td><td style=\"text-align: right;\">     0.0134274 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.755328</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        14.0863 </td><td style=\"text-align: right;\">1.1729 </td></tr>\n",
       "<tr><td>train_model_c8ebe637</td><td>TERMINATED</td><td>172.19.2.2:9111 </td><td style=\"text-align: right;\">          0.703639</td><td style=\"text-align: right;\">     0.00616272</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">          2000</td><td style=\"text-align: right;\">   0.831458</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        59.0749 </td><td style=\"text-align: right;\">1.16451</td></tr>\n",
       "<tr><td>train_model_6f1e0151</td><td>TERMINATED</td><td>172.19.2.2:9200 </td><td style=\"text-align: right;\">          0.651816</td><td style=\"text-align: right;\">     0.00750406</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">          2000</td><td style=\"text-align: right;\">   0.985159</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        40.2781 </td><td style=\"text-align: right;\">1.16791</td></tr>\n",
       "<tr><td>train_model_172aba9e</td><td>TERMINATED</td><td>172.19.2.2:9288 </td><td style=\"text-align: right;\">          0.964572</td><td style=\"text-align: right;\">     0.159848  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.630505</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.97601</td><td style=\"text-align: right;\">1.16223</td></tr>\n",
       "<tr><td>train_model_5fb93b42</td><td>TERMINATED</td><td>172.19.2.2:9373 </td><td style=\"text-align: right;\">          0.762696</td><td style=\"text-align: right;\">     0.014614  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.674565</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.2227 </td><td style=\"text-align: right;\">1.14621</td></tr>\n",
       "<tr><td>train_model_ffb78089</td><td>TERMINATED</td><td>172.19.2.2:9458 </td><td style=\"text-align: right;\">          0.750049</td><td style=\"text-align: right;\">     0.0138849 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.70675 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        14.124  </td><td style=\"text-align: right;\">1.17001</td></tr>\n",
       "<tr><td>train_model_24f2c9c4</td><td>TERMINATED</td><td>172.19.2.2:9543 </td><td style=\"text-align: right;\">          0.790595</td><td style=\"text-align: right;\">     0.0159426 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.712079</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        22.5183 </td><td style=\"text-align: right;\">1.16829</td></tr>\n",
       "<tr><td>train_model_ad9aea5e</td><td>TERMINATED</td><td>172.19.2.2:9629 </td><td style=\"text-align: right;\">          0.821164</td><td style=\"text-align: right;\">     0.0168211 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.756997</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        21.9593 </td><td style=\"text-align: right;\">1.17102</td></tr>\n",
       "<tr><td>train_model_609b57cb</td><td>TERMINATED</td><td>172.19.2.2:9715 </td><td style=\"text-align: right;\">          0.821235</td><td style=\"text-align: right;\">     0.00539188</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.765141</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.5805 </td><td style=\"text-align: right;\">1.13709</td></tr>\n",
       "<tr><td>train_model_3e5463ac</td><td>TERMINATED</td><td>172.19.2.2:9800 </td><td style=\"text-align: right;\">          0.693461</td><td style=\"text-align: right;\">     0.029782  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.874404</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.1814 </td><td style=\"text-align: right;\">1.16756</td></tr>\n",
       "<tr><td>train_model_57dc65fc</td><td>TERMINATED</td><td>172.19.2.2:9885 </td><td style=\"text-align: right;\">          0.693653</td><td style=\"text-align: right;\">     0.030449  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          1000</td><td style=\"text-align: right;\">   0.88691 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        18.9131 </td><td style=\"text-align: right;\">1.1672 </td></tr>\n",
       "<tr><td>train_model_94495c6b</td><td>TERMINATED</td><td>172.19.2.2:9970 </td><td style=\"text-align: right;\">          0.744001</td><td style=\"text-align: right;\">     0.010777  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">          1000</td><td style=\"text-align: right;\">   0.667249</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        29.4995 </td><td style=\"text-align: right;\">1.16947</td></tr>\n",
       "<tr><td>train_model_9cdf5a5a</td><td>TERMINATED</td><td>172.19.2.2:10057</td><td style=\"text-align: right;\">          0.611033</td><td style=\"text-align: right;\">     0.00863252</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.661131</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        33.3018 </td><td style=\"text-align: right;\">1.17441</td></tr>\n",
       "<tr><td>train_model_2d5e56dd</td><td>TERMINATED</td><td>172.19.2.2:10144</td><td style=\"text-align: right;\">          0.600022</td><td style=\"text-align: right;\">     0.0745705 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.774004</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.6888 </td><td style=\"text-align: right;\">1.1621 </td></tr>\n",
       "<tr><td>train_model_c3ef657f</td><td>TERMINATED</td><td>172.19.2.2:10229</td><td style=\"text-align: right;\">          0.60678 </td><td style=\"text-align: right;\">     0.00971154</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.739586</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        31.6305 </td><td style=\"text-align: right;\">1.16838</td></tr>\n",
       "<tr><td>train_model_d0d864dd</td><td>TERMINATED</td><td>172.19.2.2:10316</td><td style=\"text-align: right;\">          0.648971</td><td style=\"text-align: right;\">     0.00986329</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.704268</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        31.6797 </td><td style=\"text-align: right;\">1.16907</td></tr>\n",
       "<tr><td>train_model_f2e128c0</td><td>TERMINATED</td><td>172.19.2.2:10403</td><td style=\"text-align: right;\">          0.628598</td><td style=\"text-align: right;\">     0.0115315 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.670054</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        27.9203 </td><td style=\"text-align: right;\">1.17113</td></tr>\n",
       "<tr><td>train_model_538f5827</td><td>TERMINATED</td><td>172.19.2.2:10490</td><td style=\"text-align: right;\">          0.636074</td><td style=\"text-align: right;\">     0.00535848</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.653402</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        33.6844 </td><td style=\"text-align: right;\">1.17225</td></tr>\n",
       "<tr><td>train_model_237f1e10</td><td>TERMINATED</td><td>172.19.2.2:10577</td><td style=\"text-align: right;\">          0.726965</td><td style=\"text-align: right;\">     0.0050583 </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">          1500</td><td style=\"text-align: right;\">   0.641791</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        29.1767 </td><td style=\"text-align: right;\">1.16318</td></tr>\n",
       "<tr><td>train_model_2b42e535</td><td>TERMINATED</td><td>172.19.2.2:10664</td><td style=\"text-align: right;\">          0.7295  </td><td style=\"text-align: right;\">     0.0195927 </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.603552</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        12.1507 </td><td style=\"text-align: right;\">1.16847</td></tr>\n",
       "<tr><td>train_model_84ec951b</td><td>TERMINATED</td><td>172.19.2.2:10749</td><td style=\"text-align: right;\">          0.675487</td><td style=\"text-align: right;\">     0.0210622 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">   0.603535</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        23.4267 </td><td style=\"text-align: right;\">1.16856</td></tr>\n",
       "<tr><td>train_model_4b0dc2cf</td><td>TERMINATED</td><td>172.19.2.2:10835</td><td style=\"text-align: right;\">          0.669026</td><td style=\"text-align: right;\">     0.00735147</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">          2000</td><td style=\"text-align: right;\">   0.731297</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        36.6135 </td><td style=\"text-align: right;\">1.17033</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (62 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=8336)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:51] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:53] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:36:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:37:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m [15:37:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8336)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8336)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:13] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m [15:37:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8421)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:38] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m [15:37:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8506)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8506)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:37:59] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:37:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:06] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m [15:38:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8592)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8592)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:44] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:48] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:38:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:39:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:39:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m [15:39:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8681)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:13] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m [15:39:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8767)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8767)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:39:49] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:39:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:39:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:39:53] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:39:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:39:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:39:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:40:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:40:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:40:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:40:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m [15:40:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8853)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8853)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:19] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:24] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m [15:40:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=8939)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=8939)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:50] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:53] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:40:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:41:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:41:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m [15:41:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9025)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9025)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:12] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:23] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:41:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:42:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m [15:42:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9111)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9111)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:20] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:28] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m [15:42:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9200)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9200)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:08] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:09] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m [15:43:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9288)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9288)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:26] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:27] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m [15:43:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9373)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9373)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:45] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m [15:43:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9458)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9458)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:07] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m [15:44:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9543)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:37] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m [15:44:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9629)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9629)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:08] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m [15:45:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9715)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9715)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:29] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m [15:45:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9800)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9800)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:45:49] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:45:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:45:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:45:52] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:45:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:45:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:45:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:45:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:46:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:46:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:46:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m [15:46:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9885)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9885)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:16] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:21] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m [15:46:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=9970)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=9970)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:46:53] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:46:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:46:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:46:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:46:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:47:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:47:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:47:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:47:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:47:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:47:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m [15:47:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10057)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10057)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:34] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:36] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m [15:47:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10144)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10144)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:47:55] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:47:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:01] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m [15:48:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10229)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10229)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:35] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:48:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:49:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m [15:49:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10316)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10316)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:15] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m [15:49:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10403)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10403)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:49:51] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:49:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:49:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:49:57] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:49:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:50:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:50:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:50:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:50:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:50:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:50:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m [15:50:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10490)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10490)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:33] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:38] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:50:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m [15:51:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10577)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10577)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:10] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:12] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m [15:51:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10664)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10664)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:30] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:34] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m [15:51:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10749)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10749)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:00] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m Potential solutions:\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m [15:52:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "\u001b[36m(train_model pid=10835)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(train_model pid=10835)\u001b[0m \n",
      "2025-10-19 15:52:36,917\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_model_2025-10-19_15-36-40' in 0.0132s.\n",
      "2025-10-19 15:52:36,927\tINFO tune.py:1041 -- Total run time: 956.25 seconds (955.96 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config for xgboost: {'n_estimators': 1500, 'max_depth': 4, 'learning_rate': 0.011485145069777995, 'subsample': 0.6720778331515599, 'colsample_bytree': 0.7430816334003801}\n",
      "\n",
      "Training CatBoost final folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost final folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:15] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:54:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-10-19 15:54:42,417] A new study created in memory with name: no-name-9b0067c6-c334-42ab-9063-00e0598cb499\n",
      "[I 2025-10-19 15:54:42,511] Trial 0 finished with value: 1.1757262487194244 and parameters: {'w_cat': 0.7967228226056815}. Best is trial 0 with value: 1.1757262487194244.\n",
      "[I 2025-10-19 15:54:42,595] Trial 1 finished with value: 1.1760604071959724 and parameters: {'w_cat': 0.8051349506201662}. Best is trial 1 with value: 1.1760604071959724.\n",
      "[I 2025-10-19 15:54:42,682] Trial 2 finished with value: 1.177947946136357 and parameters: {'w_cat': 0.9100529048108457}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:42,768] Trial 3 finished with value: 1.173408215194971 and parameters: {'w_cat': 0.43745584265134196}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:42,853] Trial 4 finished with value: 1.1743731298165503 and parameters: {'w_cat': 0.3984258446955167}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:42,936] Trial 5 finished with value: 1.1769414182170688 and parameters: {'w_cat': 0.15393994001711642}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:43,020] Trial 6 finished with value: 1.1752854486748916 and parameters: {'w_cat': 0.5811452689338218}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:43,111] Trial 7 finished with value: 1.1749309849267127 and parameters: {'w_cat': 0.7242861870912372}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:43,207] Trial 8 finished with value: 1.1756256864185408 and parameters: {'w_cat': 0.5723766302309724}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:43,302] Trial 9 finished with value: 1.173407437849217 and parameters: {'w_cat': 0.4369558550560203}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:43,393] Trial 10 finished with value: 1.1777713279859823 and parameters: {'w_cat': 0.9841307329137436}. Best is trial 2 with value: 1.177947946136357.\n",
      "[I 2025-10-19 15:54:43,486] Trial 11 finished with value: 1.1780806075501653 and parameters: {'w_cat': 0.9969581147691422}. Best is trial 11 with value: 1.1780806075501653.\n",
      "[I 2025-10-19 15:54:43,590] Trial 12 finished with value: 1.1780924255145695 and parameters: {'w_cat': 0.9927649561881405}. Best is trial 12 with value: 1.1780924255145695.\n",
      "[I 2025-10-19 15:54:43,683] Trial 13 finished with value: 1.1752418945411278 and parameters: {'w_cat': 0.0006036582792319223}. Best is trial 12 with value: 1.1780924255145695.\n",
      "[I 2025-10-19 15:54:43,776] Trial 14 finished with value: 1.1781070132542517 and parameters: {'w_cat': 0.987109879149673}. Best is trial 14 with value: 1.1781070132542517.\n",
      "[I 2025-10-19 15:54:43,863] Trial 15 finished with value: 1.1761510497515133 and parameters: {'w_cat': 0.6954450080273694}. Best is trial 14 with value: 1.1781070132542517.\n",
      "[I 2025-10-19 15:54:43,947] Trial 16 finished with value: 1.1782190607893765 and parameters: {'w_cat': 0.8584515037041196}. Best is trial 16 with value: 1.1782190607893765.\n",
      "[I 2025-10-19 15:54:44,031] Trial 17 finished with value: 1.1782208521480317 and parameters: {'w_cat': 0.8577001011920831}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,118] Trial 18 finished with value: 1.175371627050005 and parameters: {'w_cat': 0.3075465324247102}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,202] Trial 19 finished with value: 1.1765542572399494 and parameters: {'w_cat': 0.8231045521410922}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,291] Trial 20 finished with value: 1.1768426620636196 and parameters: {'w_cat': 0.6854540007971426}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,378] Trial 21 finished with value: 1.1781863391510414 and parameters: {'w_cat': 0.876938182271231}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,462] Trial 22 finished with value: 1.1778469730351802 and parameters: {'w_cat': 0.8740883560791602}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,551] Trial 23 finished with value: 1.1746133950746331 and parameters: {'w_cat': 0.6301305309999163}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,639] Trial 24 finished with value: 1.1773128818795866 and parameters: {'w_cat': 0.8842041470074533}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,728] Trial 25 finished with value: 1.1747241427214261 and parameters: {'w_cat': 0.7696964069069534}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,815] Trial 26 finished with value: 1.1773102477549906 and parameters: {'w_cat': 0.8856983107280338}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,902] Trial 27 finished with value: 1.1761631563343902 and parameters: {'w_cat': 0.6419035581516948}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:44,995] Trial 28 finished with value: 1.1757759238068588 and parameters: {'w_cat': 0.543448880262799}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,096] Trial 29 finished with value: 1.175913384055381 and parameters: {'w_cat': 0.784040011884984}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,183] Trial 30 finished with value: 1.1772127312694862 and parameters: {'w_cat': 0.9315594911602625}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,269] Trial 31 finished with value: 1.1763875281920897 and parameters: {'w_cat': 0.8187473339481246}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,357] Trial 32 finished with value: 1.1775614149517146 and parameters: {'w_cat': 0.929663133014164}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,444] Trial 33 finished with value: 1.1768903898668521 and parameters: {'w_cat': 0.8280703476859844}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,528] Trial 34 finished with value: 1.1752558393057557 and parameters: {'w_cat': 0.7500111731642175}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,612] Trial 35 finished with value: 1.1778621562194074 and parameters: {'w_cat': 0.9480081884338737}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,696] Trial 36 finished with value: 1.1778856796585826 and parameters: {'w_cat': 0.8514477922543022}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,780] Trial 37 finished with value: 1.1753883226666013 and parameters: {'w_cat': 0.3141954003330377}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,866] Trial 38 finished with value: 1.1779470138986894 and parameters: {'w_cat': 0.9105623222504096}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:45,959] Trial 39 finished with value: 1.1750837294474985 and parameters: {'w_cat': 0.7501483516994922}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:46,056] Trial 40 finished with value: 1.175818322822591 and parameters: {'w_cat': 0.6519404327717173}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:46,148] Trial 41 finished with value: 1.1779663791645894 and parameters: {'w_cat': 0.9754346499268446}. Best is trial 17 with value: 1.1782208521480317.\n",
      "[I 2025-10-19 15:54:46,236] Trial 42 finished with value: 1.1782504200053778 and parameters: {'w_cat': 0.9977821314475593}. Best is trial 42 with value: 1.1782504200053778.\n",
      "[I 2025-10-19 15:54:46,323] Trial 43 finished with value: 1.1783873098229565 and parameters: {'w_cat': 0.9444016673550206}. Best is trial 43 with value: 1.1783873098229565.\n",
      "[I 2025-10-19 15:54:46,410] Trial 44 finished with value: 1.1779406960403176 and parameters: {'w_cat': 0.913949367277632}. Best is trial 43 with value: 1.1783873098229565.\n",
      "[I 2025-10-19 15:54:46,496] Trial 45 finished with value: 1.1780356168836885 and parameters: {'w_cat': 0.8642804836867235}. Best is trial 43 with value: 1.1783873098229565.\n",
      "[I 2025-10-19 15:54:46,583] Trial 46 finished with value: 1.1778493800416732 and parameters: {'w_cat': 0.953968821125549}. Best is trial 43 with value: 1.1783873098229565.\n",
      "[I 2025-10-19 15:54:46,670] Trial 47 finished with value: 1.175728436447449 and parameters: {'w_cat': 0.7949085197440232}. Best is trial 43 with value: 1.1783873098229565.\n",
      "[I 2025-10-19 15:54:46,755] Trial 48 finished with value: 1.1751038952202009 and parameters: {'w_cat': 0.7222796072145473}. Best is trial 43 with value: 1.1783873098229565.\n",
      "[I 2025-10-19 15:54:46,842] Trial 49 finished with value: 1.1746851715310904 and parameters: {'w_cat': 0.48605451454613047}. Best is trial 43 with value: 1.1783873098229565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ensemble weights (CatBoost, XGBoost): (0.9444016673550206, 0.055598332644979376), Score: 1.1784\n",
      "\n",
      "===== Ensemble OOF Metrics =====\n",
      "OOF AUC: 0.7186\n",
      "OOF Gini: 0.4373\n",
      "OOF Custom Score: 1.1784\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import optuna\n",
    "\n",
    "# ---- Veri ----\n",
    "target_col = 'churn'\n",
    "cat_features = ['gender', 'work_type', 'province', 'religion', 'work_sector']\n",
    "cat_features = [c for c in cat_features if c in features]\n",
    "features = list(set(features + cat_features))\n",
    "df = train_ref_data.copy()\n",
    "X_test_orig = test_ref_data.copy()[features]\n",
    "X_orig = df.drop(target_col, axis=1)[features]\n",
    "y = df[target_col]\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ---- Ray Tune Fonksiyonu (GPU) ----\n",
    "def train_model(config, model_type=None):\n",
    "    oof_preds = np.zeros(len(X_orig))\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_orig, y):\n",
    "        X_train, X_val = X_orig.iloc[train_idx], X_orig.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        if model_type == \"catboost\":\n",
    "            model = CatBoostClassifier(\n",
    "                iterations=int(config[\"iterations\"]),\n",
    "                depth=int(config[\"depth\"]),\n",
    "                learning_rate=config[\"learning_rate\"],\n",
    "                l2_leaf_reg=config[\"l2_leaf_reg\"],\n",
    "                border_count=int(config[\"border_count\"]),\n",
    "                random_seed=42,\n",
    "                eval_metric='AUC',\n",
    "                verbose=0,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            model.fit(X_train, y_train, cat_features=cat_features, eval_set=(X_val, y_val), early_stopping_rounds=300)\n",
    "            y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        elif model_type == \"xgboost\":\n",
    "            model = xgb.XGBClassifier(\n",
    "                n_estimators=int(config[\"n_estimators\"]),\n",
    "                max_depth=int(config[\"max_depth\"]),\n",
    "                learning_rate=config[\"learning_rate\"],\n",
    "                subsample=config[\"subsample\"],\n",
    "                colsample_bytree=config[\"colsample_bytree\"],\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='auc',\n",
    "                tree_method='gpu_hist',\n",
    "                gpu_id=0,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=300, verbose=False)\n",
    "            y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        oof_preds[val_idx] = y_val_pred\n",
    "\n",
    "    # Ray Tune'a özel metric olarak raporla\n",
    "    score = ing_hubs_datathon_metric(y, oof_preds)\n",
    "    tune.report({\"score\": score})\n",
    "\n",
    "\n",
    "# ---- Arama Alanları ----\n",
    "search_spaces = {\n",
    "    \"catboost\": {\n",
    "        \"iterations\": tune.choice([500, 1000, 1500, 2000]),\n",
    "        \"depth\": tune.randint(3, 10),\n",
    "        \"learning_rate\": tune.loguniform(0.005, 0.2),\n",
    "        \"l2_leaf_reg\": tune.uniform(1, 10),\n",
    "        \"border_count\": tune.choice([64, 128, 254])\n",
    "    },\n",
    "    \"xgboost\": {\n",
    "        \"n_estimators\": tune.choice([500, 1000, 1500, 2000]),\n",
    "        \"max_depth\": tune.randint(3, 10),\n",
    "        \"learning_rate\": tune.loguniform(0.005, 0.2),\n",
    "        \"subsample\": tune.uniform(0.6, 1.0),\n",
    "        \"colsample_bytree\": tune.uniform(0.6, 1.0)\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---- Optimize Fonksiyonu ----\n",
    "def optimize_model(model_type):\n",
    "    # Scheduler artık metric ve mode ile oluşturuluyor\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=10,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "        metric=\"score\", \n",
    "        mode=\"max\"        \n",
    "    )\n",
    "\n",
    "    analysis = tune.run(\n",
    "        tune.with_parameters(train_model, model_type=model_type),\n",
    "        config=search_spaces[model_type],\n",
    "        num_samples=30,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=OptunaSearch(metric=\"score\", mode=\"max\"),\n",
    "        resources_per_trial={\"cpu\": 4, \"gpu\": 2},\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    best_config = analysis.get_best_config(metric=\"score\", mode=\"max\")\n",
    "    print(f\"Best config for {model_type}: {best_config}\")\n",
    "    return best_config\n",
    "\n",
    "\n",
    "# ---- Optimize ----\n",
    "best_cat = optimize_model(\"catboost\")\n",
    "best_xgb = optimize_model(\"xgboost\")\n",
    "\n",
    "\n",
    "# ---- Final 5-Fold Eğitim ve Ensemble ----\n",
    "models_config = {\n",
    "    \"CatBoost\": (\"catboost\", best_cat),\n",
    "    \"XGBoost\": (\"xgboost\", best_xgb)\n",
    "}\n",
    "\n",
    "all_model_oof_preds = {name: np.zeros(len(X_orig)) for name in models_config.keys()}\n",
    "all_model_test_preds = {name: [] for name in models_config.keys()}\n",
    "\n",
    "for model_name, (model_type, params) in models_config.items():\n",
    "    print(f\"\\nTraining {model_name} final folds\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_orig, y), 1):\n",
    "        X_train, X_val = X_orig.iloc[train_idx], X_orig.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        if model_type == \"catboost\":\n",
    "            model = CatBoostClassifier(\n",
    "                iterations=int(params[\"iterations\"]),\n",
    "                depth=int(params[\"depth\"]),\n",
    "                learning_rate=params[\"learning_rate\"],\n",
    "                l2_leaf_reg=params[\"l2_leaf_reg\"],\n",
    "                border_count=int(params[\"border_count\"]),\n",
    "                random_seed=42,\n",
    "                eval_metric='AUC',\n",
    "                verbose=0,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            model.fit(X_train, y_train, cat_features=cat_features, eval_set=(X_val, y_val), early_stopping_rounds=300)\n",
    "            y_val_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "        elif model_type == \"xgboost\":\n",
    "            model = xgb.XGBClassifier(\n",
    "                n_estimators=int(params[\"n_estimators\"]),\n",
    "                max_depth=int(params[\"max_depth\"]),\n",
    "                learning_rate=params[\"learning_rate\"],\n",
    "                subsample=params[\"subsample\"],\n",
    "                colsample_bytree=params[\"colsample_bytree\"],\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='auc',\n",
    "                tree_method='gpu_hist',\n",
    "                gpu_id=0,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=300, verbose=False)\n",
    "            y_val_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "        all_model_oof_preds[model_name][val_idx] = y_val_pred\n",
    "        all_model_test_preds[model_name].append(model.predict_proba(X_test_orig)[:,1])\n",
    "\n",
    "    all_model_test_preds[model_name] = np.mean(all_model_test_preds[model_name], axis=0)\n",
    "\n",
    "\n",
    "# ---- Optuna ile Ensemble Ağırlık Optimizasyonu ----\n",
    "def ensemble_objective(trial):\n",
    "    w_cat = trial.suggest_float(\"w_cat\", 0.0, 1.0)\n",
    "    w_xgb = 1.0 - w_cat\n",
    "    ensemble_oof = (w_cat*all_model_oof_preds[\"CatBoost\"] +\n",
    "                    w_xgb*all_model_oof_preds[\"XGBoost\"])\n",
    "    score = ing_hubs_datathon_metric(y, ensemble_oof)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(ensemble_objective, n_trials=50)\n",
    "\n",
    "best_weights = (study.best_params[\"w_cat\"], 1 - study.best_params[\"w_cat\"])\n",
    "best_score = study.best_value\n",
    "\n",
    "print(f\"Best ensemble weights (CatBoost, XGBoost): {best_weights}, Score: {best_score:.4f}\")\n",
    "\n",
    "ensemble_pred = (best_weights[0]*all_model_test_preds[\"CatBoost\"] +\n",
    "                 best_weights[1]*all_model_test_preds[\"XGBoost\"])\n",
    "\n",
    "# ---- Ensemble OOF Metrikleri ----\n",
    "ensemble_oof = (best_weights[0]*all_model_oof_preds[\"CatBoost\"] +\n",
    "                best_weights[1]*all_model_oof_preds[\"XGBoost\"])\n",
    "\n",
    "print(\"\\n===== Ensemble OOF Metrics =====\")\n",
    "print(f\"OOF AUC: {roc_auc_score(y, ensemble_oof):.4f}\")\n",
    "print(f\"OOF Gini: {convert_auc_to_gini(roc_auc_score(y, ensemble_oof)):.4f}\")\n",
    "print(f\"OOF Custom Score: {ing_hubs_datathon_metric(y, ensemble_oof):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T15:55:17.700028Z",
     "iopub.status.busy": "2025-10-19T15:55:17.699248Z",
     "iopub.status.idle": "2025-10-19T15:55:17.704624Z",
     "shell.execute_reply": "2025-10-19T15:55:17.703885Z",
     "shell.execute_reply.started": "2025-10-19T15:55:17.700003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 2000,\n",
       " 'depth': 6,\n",
       " 'learning_rate': 0.007484348431669206,\n",
       " 'l2_leaf_reg': 3.5135289637920772,\n",
       " 'border_count': 254}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T15:55:30.843137Z",
     "iopub.status.busy": "2025-10-19T15:55:30.842860Z",
     "iopub.status.idle": "2025-10-19T15:55:30.848102Z",
     "shell.execute_reply": "2025-10-19T15:55:30.847361Z",
     "shell.execute_reply.started": "2025-10-19T15:55:30.843119Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1500,\n",
       " 'max_depth': 4,\n",
       " 'learning_rate': 0.011485145069777995,\n",
       " 'subsample': 0.6720778331515599,\n",
       " 'colsample_bytree': 0.7430816334003801}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T16:11:01.763693Z",
     "iopub.status.busy": "2025-10-19T16:11:01.762862Z",
     "iopub.status.idle": "2025-10-19T16:11:01.768933Z",
     "shell.execute_reply": "2025-10-19T16:11:01.768267Z",
     "shell.execute_reply.started": "2025-10-19T16:11:01.763668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cc_transaction_all_cnt_rank_pct_mean_last_1m',\n",
       " 'cc_transaction_all_cnt_last_1m_max',\n",
       " 'active_product_category_nbr_max_ratio_3_12_m',\n",
       " 'mobile_eft_all_amt_real_min_ratio_1_3_m',\n",
       " 'active_product_category_nbr_last_6m_sum',\n",
       " 'mobile_eft_all_amt_real_rank_pct_mean_last_1m',\n",
       " 'active_product_category_nbr_min_ratio_1_3_m',\n",
       " 'days_since_last_transaction',\n",
       " 'active_product_category_nbr_last_9m_max',\n",
       " 'cc_transaction_all_cnt_delta_last_1m',\n",
       " 'mobile_eft_all_cnt_last_9m_mean',\n",
       " 'mobile_eft_all_cnt_ema_last_6m',\n",
       " 'mobile_eft_all_cnt_va_last_6m',\n",
       " 'active_product_category_nbr_last_12m_min',\n",
       " 'cc_transaction_all_cnt_delta_last_9m',\n",
       " 'mobile_eft_all_cnt_rank_pct_mean_last_1m',\n",
       " 'mobile_eft_all_cnt_rank_pct_mean_last_3m',\n",
       " 'mobile_eft_all_cnt_ema_last_3m',\n",
       " 'active_product_category_nbr_last_12m_max',\n",
       " 'cc_transaction_all_cnt_last_12m_max',\n",
       " 'cc_transaction_all_cnt_sum_ratio_1_9_m',\n",
       " 'cc_transaction_all_cnt_rank_pct_mean_last_12m',\n",
       " 'cc_transaction_all_cnt_delta_last_6m',\n",
       " 'mobile_eft_all_amt_real_sum_ratio_3_6_m',\n",
       " 'active_product_category_nbr_mean_ratio_3_6_m',\n",
       " 'active_product_category_nbr_mean_ratio_1_3_m',\n",
       " 'cc_transaction_all_cnt_ema_last_3m',\n",
       " 'active_product_category_nbr_max_ratio_3_9_m',\n",
       " 'cc_transaction_all_cnt_vol_last_3m',\n",
       " 'mobile_eft_avg_ratio_1_3_m',\n",
       " 'number_of_active_months',\n",
       " 'cc_transaction_all_cnt_sum_ratio_1_12_m',\n",
       " 'cc_transaction_all_cnt_sum_ratio_1_6_m',\n",
       " 'cc_transaction_all_amt_real_std_last_3m',\n",
       " 'active_product_category_nbr_max_ratio_3_6_m',\n",
       " 'cc_transaction_all_cnt_ema_last_1m',\n",
       " 'cc_transaction_all_cnt_vol_last_12m',\n",
       " 'active_product_category_nbr_min_ratio_1_6_m',\n",
       " 'months_with_transaction',\n",
       " 'interaction_tenure_active',\n",
       " 'cc_transaction_all_cnt_last_9m_max',\n",
       " 'active_product_category_nbr_last_3m_mean',\n",
       " 'active_product_category_nbr_last_3m_max',\n",
       " 'mobile_eft_all_cnt_ema_last_9m',\n",
       " 'active_product_category_nbr_last_3m_sum',\n",
       " 'cc_transaction_avg_amt_last_1m',\n",
       " 'active_product_category_nbr_last_12m_mean',\n",
       " 'active_product_category_nbr_last_9m_sum',\n",
       " 'active_product_category_nbr_last_9m_mean',\n",
       " 'mobile_eft_all_amt_real_sum_ratio_1_6_m',\n",
       " 'age',\n",
       " 'cc_transaction_all_cnt_trend_dir_last_1m',\n",
       " 'active_product_category_nbr_min_ratio_1_12_m',\n",
       " 'mobile_eft_all_amt_real_mean_ratio_1_6_m',\n",
       " 'active_product_category_nbr_last_1m_mean',\n",
       " 'active_product_category_nbr_last_12m_sum',\n",
       " 'active_product_category_nbr_last_6m_mean',\n",
       " 'mobile_eft_all_cnt_ema_last_12m',\n",
       " 'mobile_eft_all_cnt_rank_pct_mean_last_12m',\n",
       " 'active_product_category_nbr_last_6m_max']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T15:58:08.038370Z",
     "iopub.status.busy": "2025-10-19T15:58:08.037725Z",
     "iopub.status.idle": "2025-10-19T15:58:08.144477Z",
     "shell.execute_reply": "2025-10-19T15:58:08.143868Z",
     "shell.execute_reply.started": "2025-10-19T15:58:08.038345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/kaggle/input/ing-hubs-turkiye-datathon/sample_submission.csv')\n",
    "sub['churn'] = ensemble_pred\n",
    "sub.to_csv('ensemble_v8_catboost_xgb_ray_tuned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T15:59:39.303761Z",
     "iopub.status.busy": "2025-10-19T15:59:39.303435Z",
     "iopub.status.idle": "2025-10-19T15:59:41.836101Z",
     "shell.execute_reply": "2025-10-19T15:59:41.835277Z",
     "shell.execute_reply.started": "2025-10-19T15:59:39.303736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.08M/1.08M [00:00<00:00, 2.71MB/s]\n",
      "Successfully submitted to ING Hubs Türkiye Datathon"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "kaggle_file = \"/kaggle/input/kagglejson/kaggle (2).json\"\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "shutil.copy(kaggle_file, os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n",
    "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n",
    "\n",
    "!kaggle competitions submit -c ing-hubs-turkiye-datathon -f /kaggle/working/ensemble_v8_catboost_xgb_ray_tuned.csv -m \"ray_tune_hill_climbing\""
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13860829,
     "isSourceIdPinned": false,
     "sourceId": 116092,
     "sourceType": "competition"
    },
    {
     "datasetId": 8051497,
     "sourceId": 12737450,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8524457,
     "sourceId": 13430705,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8532299,
     "sourceId": 13442298,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8532800,
     "sourceId": 13443009,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
